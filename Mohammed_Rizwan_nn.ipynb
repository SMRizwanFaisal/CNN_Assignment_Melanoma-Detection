{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import Augmentor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Defining the path for train and test images \n",
    "data_dir_train = pathlib.Path(\"C:/Users/Mohammad Rizwan/Downloads/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\") \n",
    "data_dir_test = pathlib.Path('C:/Users/Mohammad Rizwan/Downloads/Skin cancer ISIC The International Skin Imaging Collaboration/Test/')   \n",
    "path_to_training_dataset = \"C:/Users/Mohammad Rizwan/Downloads/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Check the number of images\n",
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(f'Train Image Count: {image_count_train}')\n",
    "print(f'Test Image Count: {image_count_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Creating the training and validation datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_train,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_train,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Checking the class names\n",
    "class_names = train_ds.class_names\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Visualize one instance of all classes\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Optimize data loading\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Build a CNN model\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Regularization layer to reduce overfitting\n",
    "    layers.Dense(9, activation='softmax')  # Output layer for 9 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Visualize training results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Apply Data Augmentation to combat overfitting/underfitting\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width, 3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Visualize data augmentation on an image\n",
    "for image, _ in train_ds.take(1):\n",
    "    augmented_image = data_augmentation(image)\n",
    "    plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Build the augmented model\n",
    "model_augmented = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(9, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Compile the augmented model\n",
    "model_augmented.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the augmented model\n",
    "history_augmented = model_augmented.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Visualize results of augmented model training\n",
    "acc_aug = history_augmented.history['accuracy']\n",
    "val_acc_aug = history_augmented.history['val_accuracy']\n",
    "loss_aug = history_augmented.history['loss']\n",
    "val_loss_aug = history_augmented.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc_aug, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc_aug, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss_aug, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss_aug, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "for i, name in enumerate(class_names):\n",
    "    class_count = len(list(data_dir_train.glob(f'{name}/*.jpg')))\n",
    "    print(f'Class {name}: {class_count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Using Augmentor to balance classes\n",
    "\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + '/' + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Recheck the dataset size after augmentation\n",
    "image_count_train_aug = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(f\"Augmented Train Image Count: {image_count_train_aug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Retrain the model with the augmented balanced dataset\n",
    "train_ds_aug = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds_aug = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Rebuild the final model for balanced data\n",
    "final_model = Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(9, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Compile final model\n",
    "final_model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the final model with balanced data\n",
    "epochs = 30\n",
    "history_final = final_model.fit(\n",
    "    train_ds_aug,\n",
    "    validation_data=val_ds_aug,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "outputs": [],
   "source": [
    "# Visualize final training results\n",
    "acc_final = history_final.history['accuracy']\n",
    "val_acc_final = history_final.history['val_accuracy']\n",
    "loss_final = history_final.history['loss']\n",
    "val_loss_final = history_final.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc_final, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc_final, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Final Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss_final, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss_final, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Final Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nV2BHg1dWrdY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Starter code Assignment CNN Skin Cancer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
